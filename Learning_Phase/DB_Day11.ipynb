{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5940ab00-8744-4cad-8362-3c4b7fe28992",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Setup & Statistical Profiling\n",
    "**Task**: Calculate statistical summaries. **Concept**: .describe() gives us the \"Five Number Summary\". It is the fastest way to catch data quality issues (like negative prices)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d7cf9dd-99ae-4f01-afcc-2adbf2a75659",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, dayofweek, hour, log, unix_timestamp, first, when, count, avg, lit, corr\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Setup context\n",
    "spark.sql(\"USE CATALOG course_catalog\")\n",
    "spark.sql(\"USE SCHEMA ecommerce_governed\")\n",
    "\n",
    "# Load Silver Data (Cleaned events)\n",
    "df_events = spark.table(\"silver_events\")\n",
    "\n",
    "print(\"ðŸ“Š STATISTICAL PROFILE (Price):\")\n",
    "# 1. Descriptive Statistics for Price\n",
    "# We filter out free items to get a true sense of 'products for sale'\n",
    "df_events.filter(col(\"price\") > 0).select(\"price\").summary().show()\n",
    "\n",
    "print(\"ðŸ” outlier Detection:\")\n",
    "# Find the most expensive items to verify they are real\n",
    "display(\n",
    "    df_events.orderBy(col(\"price\").desc()).limit(5).select(\"product_id\", \"category_code\", \"brand\", \"price\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f0e1cc7c-6aca-42f9-bb91-4d6fca55dca9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Hypothesis Testing (Weekday vs. Weekend)\n",
    "**Task**: Test if conversion rates differ between weekdays and weekends. **Concept**: We create a flag is_weekend (Sunday=1, Saturday=7) and compare the Purchase/View ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14d220fa-f063-4ac3-bba0-a23d43acb8ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%python\n__backend_agg_display_orig = display\n__backend_agg_dfs = []\ndef __backend_agg_display_new(df):\n    __backend_agg_df_modules = [\"pandas.core.frame\", \"databricks.koalas.frame\", \"pyspark.sql.dataframe\", \"pyspark.pandas.frame\", \"pyspark.sql.connect.dataframe\"]\n    if (type(df).__module__ in __backend_agg_df_modules and type(df).__name__ == 'DataFrame') or isinstance(df, list):\n        __backend_agg_dfs.append(df)\n\ndisplay = __backend_agg_display_new\n\ndef __backend_agg_user_code_fn():\n    import base64\n    exec(base64.standard_b64decode(\"IyAtLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0KIyBIWVBPVEhFU0lTIFRFU1Q6ICJXZWVrZW5kIFdhcnJpb3JzIgojIEFzc3VtcHRpb246IFBlb3BsZSBicm93c2Ugb24gd2Vla2RheXMgYnV0IGJ1eSBvbiB3ZWVrZW5kcy4KIyAtLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0KCiMgMS4gRmVhdHVyZSBDcmVhdGlvbjogQWRkIFdlZWtlbmQgRmxhZwojIFNwYXJrIGRheW9md2VlazogMT1TdW5kYXksIDc9U2F0dXJkYXkKZGZfaHlwb3RoZXNpcyA9IGRmX2V2ZW50cy53aXRoQ29sdW1uKAogICAgImlzX3dlZWtlbmQiLCAKICAgIHdoZW4oZGF5b2Z3ZWVrKGNvbCgiZXZlbnRfZGF0ZSIpKS5pc2luKFsxLCA3XSksICJXZWVrZW5kIikub3RoZXJ3aXNlKCJXZWVrZGF5IikKKQoKIyAyLiBBZ2dyZWdhdGlvbjogQ2FsY3VsYXRlIENvbnZlcnNpb24gUmF0ZSBwZXIgR3JvdXAKZGZfdGVzdF9yZXN1bHRzID0gZGZfaHlwb3RoZXNpcy5ncm91cEJ5KCJpc193ZWVrZW5kIikuYWdnKAogICAgY291bnQod2hlbihjb2woImV2ZW50X3R5cGUiKSA9PSAidmlldyIsIDEpKS5hbGlhcygidmlld3MiKSwKICAgIGNvdW50KHdoZW4oY29sKCJldmVudF90eXBlIikgPT0gInB1cmNoYXNlIiwgMSkpLmFsaWFzKCJwdXJjaGFzZXMiKQopLndpdGhDb2x1bW4oCiAgICAiY29udmVyc2lvbl9yYXRlX3BjdCIsIAogICAgKGNvbCgicHVyY2hhc2VzIikgLyBjb2woInZpZXdzIikpICogMTAwCikKCnByaW50KCLwn6eqIEhZUE9USEVTSVMgUkVTVUxUUzoiKQpkaXNwbGF5KGRmX3Rlc3RfcmVzdWx0cykKCiMgVklTVUFMSVpBVElPTiBUSVA6CiMgQ3JlYXRlIGEgQmFyIENoYXJ0LiBYLUF4aXM6IGlzX3dlZWtlbmQuIFktQXhpczogY29udmVyc2lvbl9yYXRlX3BjdC4KIyBUaGlzIHZpc3VhbGx5IHByb3Zlcy9kaXNwcm92ZXMgaWYgd2Vla2VuZHMgYXJlIGJldHRlciBmb3Igc2FsZXMu\").decode())\n\ntry:\n    # run user code\n    __backend_agg_user_code_fn()\n\n    #reset display function\n    display = __backend_agg_display_orig\n\n    if len(__backend_agg_dfs) > 0:\n        # create a temp view\n        if type(__backend_agg_dfs[0]).__module__ == \"databricks.koalas.frame\":\n            # koalas dataframe\n            __backend_agg_dfs[0].to_spark().createOrReplaceTempView(\"DatabricksView9022469\")\n        elif type(__backend_agg_dfs[0]).__module__ == \"pandas.core.frame\" or isinstance(__backend_agg_dfs[0], list):\n            # pandas dataframe\n            spark.createDataFrame(__backend_agg_dfs[0]).createOrReplaceTempView(\"DatabricksView9022469\")\n        else:\n            __backend_agg_dfs[0].createOrReplaceTempView(\"DatabricksView9022469\")\n        #run backend agg\n        display(spark.sql(\"\"\"WITH q AS (select * from DatabricksView9022469) SELECT `is_weekend`,SUM(`conversion_rate_pct`) `column_42dbc0e328` FROM q GROUP BY `is_weekend`\"\"\"))\n    else:\n        displayHTML(\"dataframe no longer exists. If you're using dataframe.display(), use display(dataframe) instead.\")\n\n\nfinally:\n    spark.sql(\"drop view if exists DatabricksView9022469\")\n    display = __backend_agg_display_orig\n    del __backend_agg_display_new\n    del __backend_agg_display_orig\n    del __backend_agg_dfs\n    del __backend_agg_user_code_fn\n\n",
       "commandTitle": "Visualization 1",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "CHART"
         },
         {
          "key": "options",
          "value": {
           "alignYAxesAtZero": true,
           "coefficient": 1,
           "columnConfigurationMap": {
            "x": {
             "column": "is_weekend",
             "id": "column_42dbc0e326"
            },
            "y": [
             {
              "column": "conversion_rate_pct",
              "id": "column_42dbc0e328",
              "transform": "SUM"
             }
            ]
           },
           "dateTimeFormat": "DD/MM/YYYY HH:mm",
           "direction": {
            "type": "counterclockwise"
           },
           "error_y": {
            "type": "data",
            "visible": true
           },
           "globalSeriesType": "column",
           "isAggregationOn": true,
           "legend": {
            "traceorder": "normal"
           },
           "missingValuesAsZero": true,
           "numberFormat": "0,0.[00000]",
           "percentFormat": "0[.]00%",
           "series": {
            "error_y": {
             "type": "data",
             "visible": true
            },
            "stacking": null
           },
           "seriesOptions": {
            "column_42dbc0e328": {
             "type": "column",
             "yAxis": 0
            }
           },
           "showDataLabels": false,
           "sizemode": "diameter",
           "sortX": true,
           "sortY": true,
           "swappedAxes": false,
           "textFormat": "",
           "useAggregationsUi": true,
           "valuesOptions": {},
           "version": 2,
           "xAxis": {
            "labels": {
             "enabled": true
            },
            "type": "-"
           },
           "yAxis": [
            {
             "type": "-"
            },
            {
             "opposite": true,
             "type": "-"
            }
           ]
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "275",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestAssumeRoleInfo": null,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {},
       "nuid": "c9e43950-28cc-409f-b83a-8787c380cde9",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 6,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {
        "queryPlan": {
         "groups": [
          {
           "column": "is_weekend",
           "type": "column"
          }
         ],
         "selects": [
          {
           "column": "is_weekend",
           "type": "column"
          },
          {
           "alias": "column_42dbc0e328",
           "args": [
            {
             "column": "conversion_rate_pct",
             "type": "column"
            }
           ],
           "function": "SUM",
           "type": "function"
          }
         ]
        }
       },
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "373",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# HYPOTHESIS TEST: \"Weekend Warriors\"\n",
    "# Assumption: People browse on weekdays but buy on weekends.\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# 1. Feature Creation: Add Weekend Flag\n",
    "# Spark dayofweek: 1=Sunday, 7=Saturday\n",
    "df_hypothesis = df_events.withColumn(\n",
    "    \"is_weekend\", \n",
    "    when(dayofweek(col(\"event_date\")).isin([1, 7]), \"Weekend\")\n",
    "    .otherwise(\"Weekday\")\n",
    ")\n",
    "\n",
    "# 2. Aggregation: Calculate Conversion Rate per Group\n",
    "df_test_results = df_hypothesis.groupBy(\"is_weekend\").agg(\n",
    "    count(when(col(\"event_type\") == \"view\", 1)).alias(\"views\"),\n",
    "    count(when(col(\"event_type\") == \"purchase\", 1)).alias(\"purchases\")\n",
    ").withColumn(\n",
    "    \"conversion_rate_pct\", \n",
    "    (col(\"purchases\") / col(\"views\")) * 100\n",
    ")\n",
    "\n",
    "print(\"ðŸ§ª HYPOTHESIS RESULTS:\")\n",
    "display(df_test_results)\n",
    "\n",
    "# VISUALIZATION TIP:\n",
    "# Create a Bar Chart. X-Axis: is_weekend. Y-Axis: conversion_rate_pct.\n",
    "# This visually proves/disproves if weekends are better for sales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b10a21f-3a3e-4709-8f97-0e46e79479f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Correlation Analysis\n",
    "**Task**: Identify correlations. **Concept**: corr() calculates the Pearson Correlation Coefficient (-1 to 1). A value near -1 means \"As Price goes UP, Sales go DOWN.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e9098c5-e1c8-43e7-b6ab-2b46be9bfd0e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%python\n__backend_agg_display_orig = display\n__backend_agg_dfs = []\ndef __backend_agg_display_new(df):\n    __backend_agg_df_modules = [\"pandas.core.frame\", \"databricks.koalas.frame\", \"pyspark.sql.dataframe\", \"pyspark.pandas.frame\", \"pyspark.sql.connect.dataframe\"]\n    if (type(df).__module__ in __backend_agg_df_modules and type(df).__name__ == 'DataFrame') or isinstance(df, list):\n        __backend_agg_dfs.append(df)\n\ndisplay = __backend_agg_display_new\n\ndef __backend_agg_user_code_fn():\n    import base64\n    exec(base64.standard_b64decode(\"IyAtLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0KIyBDT1JSRUxBVElPTiBDSEVDSwojIFF1ZXN0aW9uOiBEb2VzIHByaWNlIG5lZ2F0aXZlbHkgaW1wYWN0IHRoZSB2b2x1bWUgb2YgcHVyY2hhc2VzPwojIC0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLS0tLQoKIyBXZSBuZWVkIHRvIGFnZ3JlZ2F0ZSBmaXJzdCBiZWNhdXNlICdwdXJjaGFzZScgaXMgYW4gZXZlbnQsIG5vdCBhIG51bWJlciBvbiB0aGUgdmlldyByb3cuCnByb2R1Y3Rfc3RhdHMgPSBkZl9ldmVudHMuZ3JvdXBCeSgicHJvZHVjdF9pZCIpLmFnZygKICAgIGF2ZygicHJpY2UiKS5hbGlhcygiYXZnX3ByaWNlIiksCiAgICBjb3VudCh3aGVuKGNvbCgiZXZlbnRfdHlwZSIpID09ICJwdXJjaGFzZSIsIDEpKS5hbGlhcygicHVyY2hhc2VfY291bnQiKQopCgojIENhbGN1bGF0ZSBDb3JyZWxhdGlvbgpjb3JyZWxhdGlvbl92YWwgPSBwcm9kdWN0X3N0YXRzLnN0YXQuY29ycigiYXZnX3ByaWNlIiwgInB1cmNoYXNlX2NvdW50IikKCnByaW50KGYi8J+TiSBQcmljZSB2cy4gU2FsZXMgVm9sdW1lIENvcnJlbGF0aW9uOiB7Y29ycmVsYXRpb25fdmFsOi40Zn0iKQpwcmludCgiICAgKEludGVycHJldGF0aW9uOiBWYWx1ZXMgY2xvc2UgdG8gMCBtZWFuIHdlYWsgcmVsYXRpb25zaGlwLCBjbG9zZSB0byAtMSBtZWFuIHN0cm9uZyBpbnZlcnNlIHJlbGF0aW9uc2hpcCkiKQoKIyBWaXN1YWwgU2NhdHRlciBQbG90CmRpc3BsYXkocHJvZHVjdF9zdGF0cy5zYW1wbGUoMC4wMSkuc2VsZWN0KCJhdmdfcHJpY2UiLCAicHVyY2hhc2VfY291bnQiKSkKIyBQbG90IFRpcDogU2NhdHRlciBQbG90LiBYPWF2Z19wcmljZSwgWT1wdXJjaGFzZV9jb3VudC4=\").decode())\n\ntry:\n    # run user code\n    __backend_agg_user_code_fn()\n\n    #reset display function\n    display = __backend_agg_display_orig\n\n    if len(__backend_agg_dfs) > 0:\n        # create a temp view\n        if type(__backend_agg_dfs[0]).__module__ == \"databricks.koalas.frame\":\n            # koalas dataframe\n            __backend_agg_dfs[0].to_spark().createOrReplaceTempView(\"DatabricksView50891ba\")\n        elif type(__backend_agg_dfs[0]).__module__ == \"pandas.core.frame\" or isinstance(__backend_agg_dfs[0], list):\n            # pandas dataframe\n            spark.createDataFrame(__backend_agg_dfs[0]).createOrReplaceTempView(\"DatabricksView50891ba\")\n        else:\n            __backend_agg_dfs[0].createOrReplaceTempView(\"DatabricksView50891ba\")\n        #run backend agg\n        display(spark.sql(\"\"\"WITH q AS (select * from DatabricksView50891ba) SELECT `avg_price`,`purchase_count` FROM q\"\"\"))\n    else:\n        displayHTML(\"dataframe no longer exists. If you're using dataframe.display(), use display(dataframe) instead.\")\n\n\nfinally:\n    spark.sql(\"drop view if exists DatabricksView50891ba\")\n    display = __backend_agg_display_orig\n    del __backend_agg_display_new\n    del __backend_agg_display_orig\n    del __backend_agg_dfs\n    del __backend_agg_user_code_fn\n\n",
       "commandTitle": "Visualization 1",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "CHART"
         },
         {
          "key": "options",
          "value": {
           "alignYAxesAtZero": true,
           "coefficient": 1,
           "columnConfigurationMap": {
            "x": {
             "column": "avg_price",
             "id": "column_42dbc0e336"
            },
            "y": [
             {
              "column": "purchase_count",
              "id": "column_42dbc0e337"
             }
            ]
           },
           "dateTimeFormat": "DD/MM/YYYY HH:mm",
           "direction": {
            "type": "counterclockwise"
           },
           "error_y": {
            "type": "data",
            "visible": true
           },
           "globalSeriesType": "scatter",
           "legend": {
            "traceorder": "normal"
           },
           "missingValuesAsZero": true,
           "numberFormat": "0,0.[00000]",
           "percentFormat": "0[.]00%",
           "series": {
            "error_y": {
             "type": "data",
             "visible": true
            },
            "stacking": null
           },
           "seriesOptions": {
            "column_42dbc0e337": {
             "name": "purchase_count",
             "yAxis": 0
            }
           },
           "showDataLabels": false,
           "sizemode": "diameter",
           "sortX": true,
           "sortY": true,
           "swappedAxes": false,
           "textFormat": "",
           "useAggregationsUi": true,
           "valuesOptions": {},
           "version": 2,
           "xAxis": {
            "labels": {
             "enabled": true
            },
            "type": "-"
           },
           "yAxis": [
            {
             "type": "-"
            },
            {
             "opposite": true,
             "type": "-"
            }
           ]
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "379",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestAssumeRoleInfo": null,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {},
       "nuid": "b9d03520-2883-470d-9651-d5bbfef8c915",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 8,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {
        "queryPlan": {
         "selects": [
          {
           "column": "avg_price",
           "type": "column"
          },
          {
           "column": "purchase_count",
           "type": "column"
          }
         ]
        }
       },
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "684",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# CORRELATION CHECK\n",
    "# Question: Does price negatively impact the volume of purchases?\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# We need to aggregate first because 'purchase' is an event, \n",
    "# not a number on the view row.\n",
    "product_stats = df_events.groupBy(\"product_id\").agg(\n",
    "    avg(\"price\").alias(\"avg_price\"),\n",
    "    count(when(col(\"event_type\") == \"purchase\", 1)).alias(\"purchase_count\")\n",
    ")\n",
    "\n",
    "# Calculate Correlation\n",
    "correlation_val = product_stats.stat.corr(\"avg_price\", \"purchase_count\")\n",
    "\n",
    "print(f\"ðŸ“‰ Price vs. Sales Volume Correlation: {correlation_val:.4f}\")\n",
    "print(\"\"\"   (Interpretation: Values close to 0 mean weak relationship,\n",
    "       close to -1 mean strong inverse relationship)\"\"\")\n",
    "\n",
    "# Visual Scatter Plot\n",
    "display(product_stats.sample(0.01).select(\"avg_price\", \"purchase_count\"))\n",
    "# Plot Tip: Scatter Plot. X=avg_price, Y=purchase_count."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "02fa7bb9-a38d-4add-bcac-0f9ab980f860",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Feature Engineering for ML\n",
    "**Task**: Engineer features (Log Price, Time Lags). **Concept**:\n",
    "\n",
    "* **Log Price**: Prices are \"right-skewed\" (many cheap items, few super expensive ones). Taking the log() makes the distribution normal, which helps ML models learn better.\n",
    "\n",
    "* **Time Since First View**: This is a powerful \"Behavioral Feature.\" A user who has been browsing for 10 minutes is more likely to buy than someone who just arrived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9fb38588-bf63-4a22-9d36-4dbab1db9f12",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# FEATURE ENGINEERING PIPELINE\n",
    "# Goal: Create a rich dataset for tomorrow's ML Model\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# 1. Define Window for Behavioral Features\n",
    "# Partition by User, Ordered by Time\n",
    "user_window = Window.partitionBy(\"user_id\").orderBy(\"event_time\")\n",
    "\n",
    "# 2. Create Features\n",
    "df_features = df_events \\\n",
    "    .withColumn(\"hour_of_day\", hour(\"event_time\")) \\\n",
    "    .withColumn(\"day_of_week\", dayofweek(\"event_date\")) \\\n",
    "    .withColumn(\"is_weekend_flag\", when(col(\"day_of_week\").isin([1, 7]), 1).otherwise(0)) \\\n",
    "    .withColumn(\"price_log\", log(col(\"price\") + 1)) \\\n",
    "    .withColumn(\"time_since_first_interaction\", \n",
    "                # Current Time - First Time seen in this window\n",
    "                unix_timestamp(\"event_time\") - \n",
    "                unix_timestamp(first(\"event_time\").over(user_window))\n",
    "    )\n",
    "\n",
    "# 3. Save Feature Store (Ready for ML)\n",
    "table_name = \"gold_ml_features\"\n",
    "print(f\"ðŸ’¾ Saving Engineered Features to: {table_name}...\")\n",
    "\n",
    "df_features.select(\n",
    "    \"user_id\", \"product_id\", \"brand\", \"category_code\",\n",
    "    \"hour_of_day\", \"day_of_week\", \"is_weekend_flag\", \"price_log\", \"time_since_first_interaction\",\n",
    "    \"event_type\" # Target Variable\n",
    ").write.mode(\"overwrite\").saveAsTable(table_name)\n",
    "\n",
    "print(\"âœ… Feature Engineering Complete.\")\n",
    "display(spark.table(table_name).limit(5))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Day 11",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
