{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9912a864-aea5-4f9f-8695-656a16359ada",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Create Label Column\n",
    "### Convert business event into ML label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9d7d981-4e35-4ba0-8ace-971545336201",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"MLFLOW_DFS_TMP\"] = \"/Volumes/workspace/ecommerce/ecommerce_data\"\n",
    "\n",
    "df = spark.sql(\"SELECT * FROM ecommerce_catalog.gold.vw_events_nov_analytics\")\n",
    "\n",
    "\n",
    "\n",
    "df_labeled = df.withColumn(\n",
    "    \"label\",\n",
    "    when(df.event_type == \"purchase\", 1).otherwise(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e8136015-ff3a-428a-8b84-eab13a779a02",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Feature Engineering\n",
    "\n",
    "## We will engineer meaningful features from raw columns.\n",
    "\n",
    "### Numeric Features\n",
    "- price\n",
    "\n",
    "### Categorical Features\n",
    "- brand\n",
    "\n",
    "### Category_code\n",
    "- Time Feature\n",
    "- hour (from event_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf149498-4e6b-488f-af1e-f62986b7eb8e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_features = df_labeled.withColumn(\"event_hour\", hour(\"event_time\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "31f01b43-285d-4c02-b3c2-e7e2e22bed15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Spark ML Feature Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5566b501-ba71-4cab-8127-8be7904051ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "brand_indexer = StringIndexer(\n",
    "    inputCol=\"brand\",\n",
    "    outputCol=\"brand_idx\",\n",
    "    handleInvalid=\"keep\"\n",
    ")\n",
    "\n",
    "category_indexer = StringIndexer(\n",
    "    inputCol=\"category_code\",\n",
    "    outputCol=\"category_idx\",\n",
    "    handleInvalid=\"keep\"\n",
    ")\n",
    "\n",
    "assembler_tree = VectorAssembler(\n",
    "    inputCols=[\"price\", \"event_hour\"],  # NO brand / category\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "feature_pipeline = Pipeline(stages=[\n",
    "    brand_indexer,\n",
    "    category_indexer,\n",
    "    assembler\n",
    "])\n",
    "\n",
    "RandomForestClassifier(\n",
    "    labelCol=\"label\",\n",
    "    maxBins=5000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8b240850-0e0c-4f53-8db7-d44253fab229",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Prepare Train/Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44928d3c-3247-496a-b8a8-fdff5ae6cd98",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "final_df = feature_pipeline.fit(df_features).transform(df_features)\n",
    "\n",
    "train_df, test_df = final_df.randomSplit([0.8, 0.2], seed=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dfccfd17-4fc9-4753-abde-049405c58c6a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Training 3 Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b1018e4-f8fc-4288-866a-1e1487e96f92",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import (\n",
    "    LogisticRegression,\n",
    "    RandomForestClassifier,\n",
    "    GBTClassifier\n",
    ")\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "import mlflow\n",
    "import mlflow.spark\n",
    "\n",
    "from pyspark.ml.feature import FeatureHasher\n",
    "\n",
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(labelCol=\"label\"),\n",
    "    \"RandomForest\": RandomForestClassifier(labelCol=\"label\", numTrees=50),\n",
    "    \"GBT\": GBTClassifier(labelCol=\"label\")\n",
    "}\n",
    "\n",
    "RandomForestClassifier(\n",
    "    labelCol=\"label\",\n",
    "    maxBins=5000\n",
    ")\n",
    "\n",
    "\n",
    "hasher = FeatureHasher(\n",
    "    inputCols=[\"brand\", \"category_code\"],\n",
    "    outputCol=\"hashed_features\",\n",
    "    numFeatures=256\n",
    ")\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"label\")\n",
    "results = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ec19cfea-9ce3-4be9-8f6a-6ac925c9a2ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Compare Models Using MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5cf93c2-9f1f-45de-8d3d-6e6c56e657a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for name, model in models.items():\n",
    "    with mlflow.start_run(run_name=name):\n",
    "        fitted_model = model.fit(train_df)\n",
    "        preds = fitted_model.transform(test_df)\n",
    "        \n",
    "        auc = evaluator.evaluate(preds)\n",
    "        \n",
    "        mlflow.log_metric(\"AUC\", auc)\n",
    "        mlflow.log_param(\"model_type\", name)\n",
    "        mlflow.spark.log_model(fitted_model, \"model\")\n",
    "        \n",
    "        results[name] = auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b3fb1db9-ddaf-4fd6-b629-dff206dd53b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Day_13_Databrciks_Challenge_Ml_models",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
