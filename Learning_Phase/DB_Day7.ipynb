{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4a8e44cc-cd70-4305-b1f0-8baf032778de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Widgets\n",
    "dbutils.widgets.text(\n",
    "    \"source_path\",\n",
    "    \"/Volumes/workspace/ecommerce\",\n",
    "    \"Source Path\"\n",
    ")\n",
    "dbutils.widgets.dropdown(\n",
    "    \"layer\",\n",
    "    \"bronze\",\n",
    "    [\"bronze\", \"silver\", \"gold\"],\n",
    "    \"Layer\"\n",
    ")\n",
    "\n",
    "# Read parameter values\n",
    "source_path = dbutils.widgets.get(\"source_path\")\n",
    "layer = dbutils.widgets.get(\"layer\")\n",
    "\n",
    "print(f\"Running ETL for layer: {layer} using source path: {source_path}\")\n",
    "\n",
    "# Imports\n",
    "from pyspark.sql.functions import (\n",
    "    current_timestamp,\n",
    "    col,\n",
    "    to_date,\n",
    "    sum as spark_sum,\n",
    "    count,\n",
    "    countDistinct\n",
    ")\n",
    "\n",
    "def run_layer(layer_name, source_path):\n",
    "\n",
    "    if layer_name == \"bronze\":\n",
    "        print(\"Executing Bronze Layer...\")\n",
    "\n",
    "        # Create Bronze volume\n",
    "        spark.sql(\n",
    "            \"CREATE VOLUME IF NOT EXISTS workspace.ecommerce.bronze\"\n",
    "        )\n",
    "\n",
    "        # Read raw CSV data\n",
    "        oct_df = spark.read.csv(\n",
    "            f\"{source_path}/ecommerce_data/2019-Oct.csv\",\n",
    "            header=True,\n",
    "            inferSchema=True\n",
    "        )\n",
    "\n",
    "        # Add ingestion timestamp\n",
    "        bronze_df = oct_df.withColumn(\n",
    "            \"ingestion_time\",\n",
    "            current_timestamp()\n",
    "        )\n",
    "\n",
    "        # Bronze Delta path\n",
    "        bronze_path = (\n",
    "            f\"{source_path}/bronze/ecommerce_events\"\n",
    "        )\n",
    "\n",
    "        # Write Bronze data\n",
    "        bronze_df.write \\\n",
    "            .format(\"delta\") \\\n",
    "            .mode(\"overwrite\") \\\n",
    "            .save(bronze_path)\n",
    "\n",
    "        # Sanity checks\n",
    "        print(\"Bronze row count:\", bronze_df.count())\n",
    "        display(bronze_df.limit(10))\n",
    "        bronze_df.printSchema()\n",
    "\n",
    "    elif layer_name == \"silver\":\n",
    "        print(\"Executing Silver Layer...\")\n",
    "\n",
    "        # Create Silver volume\n",
    "        spark.sql(\n",
    "            \"CREATE VOLUME IF NOT EXISTS workspace.ecommerce.silver\"\n",
    "        )\n",
    "\n",
    "        # Read Bronze data\n",
    "        bronze_df = spark.read \\\n",
    "            .format(\"delta\") \\\n",
    "            .load(f\"{source_path}/bronze/ecommerce_events\")\n",
    "\n",
    "        # Clean and validate\n",
    "        silver_df = (\n",
    "            bronze_df\n",
    "                .filter(col(\"user_id\").isNotNull())\n",
    "                .filter(\n",
    "                    col(\"event_type\").isin(\n",
    "                        \"view\", \"cart\", \"purchase\"\n",
    "                    )\n",
    "                )\n",
    "                .filter(\n",
    "                    (col(\"price\").isNull()) |\n",
    "                    (col(\"price\") >= 0)\n",
    "                )\n",
    "                .dropDuplicates()\n",
    "        )\n",
    "\n",
    "        # Silver Delta path\n",
    "        silver_path = (\n",
    "            f\"{source_path}/silver/ecommerce_events_clean\"\n",
    "        )\n",
    "\n",
    "        # Write Silver data\n",
    "        silver_df.write \\\n",
    "            .format(\"delta\") \\\n",
    "            .mode(\"overwrite\") \\\n",
    "            .save(silver_path)\n",
    "\n",
    "        # Checks\n",
    "        print(\"Bronze rows:\", bronze_df.count())\n",
    "        print(\"Silver rows:\", silver_df.count())\n",
    "        print(\n",
    "            \"Null user_id count:\",\n",
    "            silver_df.filter(\n",
    "                col(\"user_id\").isNull()\n",
    "            ).count()\n",
    "        )\n",
    "        silver_df.groupBy(\"event_type\") \\\n",
    "            .count() \\\n",
    "            .show()\n",
    "        print(\n",
    "            \"Negative price count:\",\n",
    "            silver_df.filter(\n",
    "                col(\"price\") < 0\n",
    "            ).count()\n",
    "        )\n",
    "        display(silver_df.limit(10))\n",
    "\n",
    "    elif layer_name == \"gold\":\n",
    "        print(\"Executing Gold Layer...\")\n",
    "\n",
    "        # Create Gold volume\n",
    "        spark.sql(\n",
    "            \"CREATE VOLUME IF NOT EXISTS workspace.ecommerce.gold\"\n",
    "        )\n",
    "\n",
    "        # Read Silver data\n",
    "        silver_df = spark.read \\\n",
    "            .format(\"delta\") \\\n",
    "            .load(\n",
    "                f\"{source_path}/silver/ecommerce_events_clean\"\n",
    "            )\n",
    "\n",
    "        # Aggregates for analytics\n",
    "        gold_df = (\n",
    "            silver_df\n",
    "                .filter(col(\"event_type\") == \"purchase\")\n",
    "                .withColumn(\n",
    "                    \"event_date\",\n",
    "                    to_date(\"event_time\")\n",
    "                )\n",
    "                .groupBy(\"event_date\")\n",
    "                .agg(\n",
    "                    spark_sum(\"price\")\n",
    "                        .alias(\"total_revenue\"),\n",
    "                    count(\"*\")\n",
    "                        .alias(\"total_orders\"),\n",
    "                    countDistinct(\"user_id\")\n",
    "                        .alias(\"unique_customers\")\n",
    "                )\n",
    "        )\n",
    "\n",
    "        # Gold Delta path\n",
    "        gold_path = (\n",
    "            f\"{source_path}/gold/daily_sales_metrics\"\n",
    "        )\n",
    "\n",
    "        # Write Gold data\n",
    "        gold_df.write \\\n",
    "            .format(\"delta\") \\\n",
    "            .mode(\"overwrite\") \\\n",
    "            .save(gold_path)\n",
    "\n",
    "        # Checks\n",
    "        display(\n",
    "            gold_df\n",
    "                .orderBy(\"event_date\")\n",
    "                .limit(10)\n",
    "        )\n",
    "        print(\n",
    "            \"Duplicate dates:\",\n",
    "            gold_df.count() -\n",
    "            gold_df.select(\"event_date\")\n",
    "                   .distinct()\n",
    "                   .count()\n",
    "        )\n",
    "        gold_df.select(\n",
    "            \"event_date\",\n",
    "            \"total_revenue\",\n",
    "            \"total_orders\",\n",
    "            \"unique_customers\"\n",
    "        ).summary().show()\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Unknown layer: {layer_name}\"\n",
    "        )\n",
    "\n",
    "# Execute\n",
    "run_layer(layer, source_path)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "DB_Day7",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}