ğŸš€ DataBricks Challenge Learning + Project Journey

Sponsored by Databricks Ã— CodeBasics Ã— Indian Data Club
A 14 day intensive learning sprint followed by a hands on project phase designed to build end to end proficiency in Databricks, Spark, and the Lakehouse ecosystem.

ğŸ“Œ Challenge Structure

Phase 1 Learning & Sharing
â³ 9th Jan to 22nd Jan | Hosted by Indian Data Club
Hands on learning for 14 days
Deep dive into Databricks concepts
Social sharing and community driven learning

Phase 2 Project Phase
â³ 24th Jan to 30th Jan | Hosted by CodeBasics
Build a real world end to end project
Apply Lakehouse, Spark, and ETL workflows

ğŸ“… Daily Progress Log
â­ Day 1 Platform Setup & First Steps

ğŸ“˜ Key Learnings
Why Databricks over Pandas and Hadoop
Lakehouse architecture fundamentals
Databricks workspace ecosystem
Real world use cases including Netflix, Shell, and Comcast

ğŸ› ï¸ Tasks Completed
Created Databricks Community Edition account
Explored Workspace, Compute, and Data Explorer
Created first notebook
Executed initial PySpark commands

â­ Day 2 Apache Spark Fundamentals

ğŸ“˜ Key Learnings
Spark architecture including Driver, Executors, and DAG execution
DataFrames vs RDDs and why DataFrames dominate using Catalyst Optimizer
Lazy evaluation and how Spark optimizes workload execution
Notebook magic commands such as %sql, %python, and %fs
Using col() for safe column handling, filtering, null checks, and transformations

ğŸ› ï¸ Tasks Completed
Uploaded e commerce dataset in xlsx format
Created PySpark DataFrame
Executed core operations
select()
show()
dtypes()
filter()
groupBy()
orderBy()
Used col() for clean transformations and null handling
